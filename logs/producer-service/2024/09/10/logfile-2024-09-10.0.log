2024-09-10 21:50:37 [background-preinit] [34mINFO [0;39m o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
2024-09-10 21:50:37 [main] [34mINFO [0;39m c.z.producer.ProducerApplication - Starting ProducerApplication using Java 17.0.8 with PID 50119 (/home/anduser/dev/assessment/assessment-m2/producer/target/classes started by anduser in /home/anduser/dev/assessment/assessment-m2)
2024-09-10 21:50:37 [main] [34mINFO [0;39m c.z.producer.ProducerApplication - No active profile set, falling back to 1 default profile: "default"
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 66 ms. Found 1 MongoDB repository interface.
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.zhigalko.producer.repository.CustomerRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 3 ms. Found 0 Redis repository interfaces.
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 9001 (http)
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9001"]
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.a.catalina.core.StandardService - Starting service [Tomcat]
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.28]
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2024-09-10 21:50:38 [main] [34mINFO [0;39m o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 650 ms
2024-09-10 21:50:38 [main] [34mINFO [0;39m org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.8.0-40-generic"}, "platform": "Java/Amazon.com Inc./17.0.8+7-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@54489296, com.mongodb.Jep395RecordCodecProvider@4e8598d9, com.mongodb.KotlinCodecProvider@267ff4df]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
2024-09-10 21:50:38 [cluster-ClusterId{value='66e086eecaa81f702c146204', description='null'}-localhost:27017] [34mINFO [0;39m org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=10038142}
2024-09-10 21:50:39 [main] [34mINFO [0;39m o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9001"]
2024-09-10 21:50:39 [main] [34mINFO [0;39m o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 9001 (http) with context path '/'
2024-09-10 21:50:39 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customerViewConsumer-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customerViewConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 21:50:39 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 21:50:39 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:50:39 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:50:39 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 21:50:39 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 21:50:39 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 21:50:39 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725990639357
2024-09-10 21:50:39 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Subscribed to topic(s): CustomerViewEventTopic
2024-09-10 21:50:39 [main] [34mINFO [0;39m c.z.producer.ProducerApplication - Started ProducerApplication in 1.609 seconds (process running for 2.044)
2024-09-10 21:50:39 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 21:50:39 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:50:39 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] (Re-)joining group
2024-09-10 21:50:39 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customerViewConsumer-1-f0277178-7892-42f5-91f7-86af151c4f62
2024-09-10 21:50:39 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] (Re-)joining group
2024-09-10 21:50:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Successfully joined group with generation Generation{generationId=102, memberId='consumer-customerViewConsumer-1-f0277178-7892-42f5-91f7-86af151c4f62', protocol='range'}
2024-09-10 21:50:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Finished assignment for group at generation 102: {consumer-customerViewConsumer-1-f0277178-7892-42f5-91f7-86af151c4f62=Assignment(partitions=[CustomerViewEventTopic-0, CustomerViewEventTopic-1])}
2024-09-10 21:50:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Successfully synced group in generation Generation{generationId=102, memberId='consumer-customerViewConsumer-1-f0277178-7892-42f5-91f7-86af151c4f62', protocol='range'}
2024-09-10 21:50:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Notifying assignor about the new Assignment(partitions=[CustomerViewEventTopic-0, CustomerViewEventTopic-1])
2024-09-10 21:50:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Adding newly assigned partitions: CustomerViewEventTopic-0, CustomerViewEventTopic-1
2024-09-10 21:50:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CustomerViewEventTopic-0 to the committed offset FetchPosition{offset=35, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:50:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CustomerViewEventTopic-1 to the committed offset FetchPosition{offset=20, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 21:50:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customerViewConsumer: partitions assigned: [CustomerViewEventTopic-0, CustomerViewEventTopic-1]
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.s.web.servlet.DispatcherServlet - Completed initialization in 0 ms
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m c.z.p.s.impl.CustomerServiceImpl - Received command: com.zhigalko.producer.command.UpdateCustomerAddressCommand@76efca1b
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-service-producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://127.0.0.1:8081]
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-service-producer-1] Instantiated an idempotent producer.
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.k.c.producer.ProducerConfig - These configurations '[schema.registry.url]' were supplied but are not used yet.
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725990880255
2024-09-10 21:54:40 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Producer clientId=producer-service-producer-1] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 21:54:40 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-service-producer-1] ProducerId set to 11001 with epoch 0
2024-09-10 21:54:40 [http-nio-9001-exec-2] [34mINFO [0;39m c.z.core.service.KafkaProducer - Sending kafka message on topic UpdateCustomerAddressEventTopic
2024-09-10 21:54:40 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Kafka message successfully sent on topic UpdateCustomerAddressEventTopic and value {"id": "4d37a687-9693-4533-9dd2-4dd0708fb6e4", "address": "Moscow", "timestamp": "2024-09-10T17:54:40.233529168Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32}
2024-09-10 21:54:44 [http-nio-9001-exec-3] [34mINFO [0;39m o.s.d.m.core.convert.QueryMapper - Could not map 'Customer.id'; Maybe a fragment in 'Long' is considered a simple type; Mapper continues with id
2024-09-10 21:54:44 [http-nio-9001-exec-3] [34mINFO [0;39m c.z.p.s.i.CustomerQueryServiceImpl - Saved in cached value: CustomerProjection[id=32, name=Anna, address=New York]
2024-09-10 21:54:53 [http-nio-9001-exec-4] [34mINFO [0;39m o.s.d.m.core.convert.QueryMapper - Could not map 'Customer.id'; Maybe a fragment in 'Long' is considered a simple type; Mapper continues with id
2024-09-10 21:54:53 [http-nio-9001-exec-4] [34mINFO [0;39m c.z.p.s.i.CustomerQueryServiceImpl - Saved in cached value: CustomerProjection[id=32, name=Anna, address=New York]
2024-09-10 21:54:56 [http-nio-9001-exec-5] [34mINFO [0;39m c.z.p.s.impl.CustomerServiceImpl - Received command: com.zhigalko.producer.command.UpdateCustomerAddressCommand@4c8fe88b
2024-09-10 21:54:56 [http-nio-9001-exec-5] [34mINFO [0;39m c.z.core.service.KafkaProducer - Sending kafka message on topic UpdateCustomerAddressEventTopic
2024-09-10 21:54:56 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Kafka message successfully sent on topic UpdateCustomerAddressEventTopic and value {"id": "1fbb7956-f352-40a3-b7b0-f70361ecf2ec", "address": "Moscow", "timestamp": "2024-09-10T17:54:56.984721580Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32}
2024-09-10 21:55:02 [http-nio-9001-exec-6] [34mINFO [0;39m o.s.d.m.core.convert.QueryMapper - Could not map 'Customer.id'; Maybe a fragment in 'Long' is considered a simple type; Mapper continues with id
2024-09-10 21:55:02 [http-nio-9001-exec-6] [34mINFO [0;39m c.z.p.s.i.CustomerQueryServiceImpl - Saved in cached value: CustomerProjection[id=32, name=Anna, address=New York]
2024-09-10 21:55:02 [http-nio-9001-exec-7] [34mINFO [0;39m o.s.d.m.core.convert.QueryMapper - Could not map 'Customer.id'; Maybe a fragment in 'Long' is considered a simple type; Mapper continues with id
2024-09-10 21:55:02 [http-nio-9001-exec-7] [34mINFO [0;39m c.z.p.s.i.CustomerQueryServiceImpl - Saved in cached value: CustomerProjection[id=32, name=Anna, address=New York]
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Revoke previously assigned partitions CustomerViewEventTopic-0, CustomerViewEventTopic-1
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customerViewConsumer: partitions revoked: [CustomerViewEventTopic-0, CustomerViewEventTopic-1]
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Member consumer-customerViewConsumer-1-f0277178-7892-42f5-91f7-86af151c4f62 sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customerViewConsumer-1 unregistered
2024-09-10 21:55:24 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customerViewConsumer: Consumer stopped
2024-09-10 21:55:24 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-service-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-09-10 21:55:24 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 21:55:24 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 21:55:24 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 21:55:24 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 21:55:24 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-service-producer-1 unregistered
2024-09-10 21:55:29 [background-preinit] [34mINFO [0;39m o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
2024-09-10 21:55:29 [main] [34mINFO [0;39m c.z.producer.ProducerApplication - Starting ProducerApplication using Java 17.0.8 with PID 51330 (/home/anduser/dev/assessment/assessment-m2/producer/target/classes started by anduser in /home/anduser/dev/assessment/assessment-m2)
2024-09-10 21:55:29 [main] [34mINFO [0;39m c.z.producer.ProducerApplication - No active profile set, falling back to 1 default profile: "default"
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 62 ms. Found 1 MongoDB repository interface.
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.zhigalko.producer.repository.CustomerRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 3 ms. Found 0 Redis repository interfaces.
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 9001 (http)
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9001"]
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.a.catalina.core.StandardService - Starting service [Tomcat]
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.28]
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2024-09-10 21:55:30 [main] [34mINFO [0;39m o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 719 ms
2024-09-10 21:55:30 [main] [34mINFO [0;39m org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.8.0-40-generic"}, "platform": "Java/Amazon.com Inc./17.0.8+7-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@60807fd9, com.mongodb.Jep395RecordCodecProvider@6bcdd6e4, com.mongodb.KotlinCodecProvider@1192c925]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
2024-09-10 21:55:30 [cluster-ClusterId{value='66e08812364d083e26f45633', description='null'}-localhost:27017] [34mINFO [0;39m org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=13356863}
2024-09-10 21:55:31 [main] [34mINFO [0;39m o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9001"]
2024-09-10 21:55:31 [main] [34mINFO [0;39m o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 9001 (http) with context path '/'
2024-09-10 21:55:31 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customerViewConsumer-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customerViewConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 21:55:31 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 21:55:31 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:31 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:31 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 21:55:31 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 21:55:31 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 21:55:31 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725990931552
2024-09-10 21:55:31 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Subscribed to topic(s): CustomerViewEventTopic
2024-09-10 21:55:31 [main] [34mINFO [0;39m c.z.producer.ProducerApplication - Started ProducerApplication in 1.85 seconds (process running for 2.433)
2024-09-10 21:55:31 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 21:55:31 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:55:31 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] (Re-)joining group
2024-09-10 21:55:31 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customerViewConsumer-1-f24fe5d9-9399-4cc5-a556-4d696eaa60ea
2024-09-10 21:55:31 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] (Re-)joining group
2024-09-10 21:55:33 [main] [34mINFO [0;39m c.z.consumer.ConsumerApplication - Starting ConsumerApplication using Java 17.0.8 with PID 51475 (/home/anduser/dev/assessment/assessment-m2/consumer/target/classes started by anduser in /home/anduser/dev/assessment/assessment-m2)
2024-09-10 21:55:33 [main] [34mINFO [0;39m c.z.consumer.ConsumerApplication - No active profile set, falling back to 1 default profile: "default"
2024-09-10 21:55:33 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2024-09-10 21:55:33 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 25 ms. Found 2 MongoDB repository interfaces.
2024-09-10 21:55:33 [main] [34mINFO [0;39m org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.8.0-40-generic"}, "platform": "Java/Amazon.com Inc./17.0.8+7-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@20f6f88c, com.mongodb.Jep395RecordCodecProvider@4277127c, com.mongodb.KotlinCodecProvider@4c7e978c]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
2024-09-10 21:55:33 [cluster-ClusterId{value='66e08815e9cdbc67cdd2085b', description='null'}-localhost:27017] [34mINFO [0;39m org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=13005237}
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 21:55:34 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:34 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725990934315
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Subscribed to topic(s): UpdateCustomerAddressEventTopic
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 21:55:34 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:34 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725990934327
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Subscribed to topic(s): DeleteCustomerEventTopic
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 21:55:34 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:34 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725990934335
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Subscribed to topic(s): CreateCustomerEventTopic
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 21:55:34 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:34 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725990934345
2024-09-10 21:55:34 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Subscribed to topic(s): UpdateCustomerNameEventTopic
2024-09-10 21:55:34 [main] [34mINFO [0;39m c.z.consumer.ConsumerApplication - Started ConsumerApplication in 1.164 seconds (process running for 1.62)
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-3-c9336630-91de-40f2-b8b9-a5ccd5a83a27
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-4-3af79261-7cb8-458f-ae23-37e0e24195b8
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-1-3e5149b9-884f-4bc6-a3bd-913e104e1000
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-2-16cd60b7-5ff4-423b-beea-da4a6f8e556e
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Successfully joined group with generation Generation{generationId=104, memberId='consumer-customerViewConsumer-1-f24fe5d9-9399-4cc5-a556-4d696eaa60ea', protocol='range'}
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Finished assignment for group at generation 104: {consumer-customerViewConsumer-1-f24fe5d9-9399-4cc5-a556-4d696eaa60ea=Assignment(partitions=[CustomerViewEventTopic-0, CustomerViewEventTopic-1])}
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Successfully synced group in generation Generation{generationId=104, memberId='consumer-customerViewConsumer-1-f24fe5d9-9399-4cc5-a556-4d696eaa60ea', protocol='range'}
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Notifying assignor about the new Assignment(partitions=[CustomerViewEventTopic-0, CustomerViewEventTopic-1])
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Adding newly assigned partitions: CustomerViewEventTopic-0, CustomerViewEventTopic-1
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CustomerViewEventTopic-0 to the committed offset FetchPosition{offset=35, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CustomerViewEventTopic-1 to the committed offset FetchPosition{offset=20, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 21:55:34 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customerViewConsumer: partitions assigned: [CustomerViewEventTopic-0, CustomerViewEventTopic-1]
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=90, memberId='consumer-customersConsumer-2-16cd60b7-5ff4-423b-beea-da4a6f8e556e', protocol='range'}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=90, memberId='consumer-customersConsumer-4-3af79261-7cb8-458f-ae23-37e0e24195b8', protocol='range'}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=90, memberId='consumer-customersConsumer-3-c9336630-91de-40f2-b8b9-a5ccd5a83a27', protocol='range'}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=90, memberId='consumer-customersConsumer-1-3e5149b9-884f-4bc6-a3bd-913e104e1000', protocol='range'}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Finished assignment for group at generation 90: {consumer-customersConsumer-4-3af79261-7cb8-458f-ae23-37e0e24195b8=Assignment(partitions=[UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]), consumer-customersConsumer-2-16cd60b7-5ff4-423b-beea-da4a6f8e556e=Assignment(partitions=[DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]), consumer-customersConsumer-1-3e5149b9-884f-4bc6-a3bd-913e104e1000=Assignment(partitions=[UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]), consumer-customersConsumer-3-c9336630-91de-40f2-b8b9-a5ccd5a83a27=Assignment(partitions=[CreateCustomerEventTopic-0, CreateCustomerEventTopic-1])}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=90, memberId='consumer-customersConsumer-2-16cd60b7-5ff4-423b-beea-da4a6f8e556e', protocol='range'}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=90, memberId='consumer-customersConsumer-1-3e5149b9-884f-4bc6-a3bd-913e104e1000', protocol='range'}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=90, memberId='consumer-customersConsumer-3-c9336630-91de-40f2-b8b9-a5ccd5a83a27', protocol='range'}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=90, memberId='consumer-customersConsumer-4-3af79261-7cb8-458f-ae23-37e0e24195b8', protocol='range'}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1])
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[CreateCustomerEventTopic-0, CreateCustomerEventTopic-1])
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1])
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1])
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Adding newly assigned partitions: DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Adding newly assigned partitions: UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Adding newly assigned partitions: CreateCustomerEventTopic-0, CreateCustomerEventTopic-1
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Adding newly assigned partitions: UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerNameEventTopic-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition DeleteCustomerEventTopic-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=6}}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CreateCustomerEventTopic-1 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerAddressEventTopic-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerNameEventTopic-1 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CreateCustomerEventTopic-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition DeleteCustomerEventTopic-1 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerAddressEventTopic-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]
2024-09-10 21:55:37 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.s.web.servlet.DispatcherServlet - Completed initialization in 0 ms
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m c.z.p.s.impl.CustomerServiceImpl - Received command: com.zhigalko.producer.command.UpdateCustomerAddressCommand@759ad112
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-service-producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://127.0.0.1:8081]
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-service-producer-1] Instantiated an idempotent producer.
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.k.c.producer.ProducerConfig - These configurations '[schema.registry.url]' were supplied but are not used yet.
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991005691
2024-09-10 21:56:45 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Producer clientId=producer-service-producer-1] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 21:56:45 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-service-producer-1] ProducerId set to 12001 with epoch 0
2024-09-10 21:56:45 [http-nio-9001-exec-2] [34mINFO [0;39m c.z.core.service.KafkaProducer - Sending kafka message on topic UpdateCustomerAddressEventTopic
2024-09-10 21:56:45 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Kafka message successfully sent on topic UpdateCustomerAddressEventTopic and value {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32}
2024-09-10 21:56:45 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:45 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@1cf25055
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 22, changed: Moscow
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@4c8b5765
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 23, changed: Moscow
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@18f7920c
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 24, changed: Moscow
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:56:46 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@50a84b59
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 25, changed: Moscow
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@44e02ef4
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 26, changed: Moscow
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:56:47 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@259e326e
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 27, changed: Moscow
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@28b28f08
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 28, changed: Moscow
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:56:48 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@3179402e
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 29, changed: Moscow
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@27f1660e
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 30, changed: Moscow
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:56:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:56:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 6, CreateTime = 1725991005696, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "e8642bcc-d54a-44b1-a3cd-fa06a140b2dc", "address": "Moscow", "timestamp": "2024-09-10T17:56:45.667726788Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:56:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@4bc93358
2024-09-10 21:56:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 31, changed: Moscow
2024-09-10 21:56:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.listener.DefaultErrorHandler - Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for UpdateCustomerAddressEventTopic-0@6
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:57:38 [http-nio-9001-exec-3] [34mINFO [0;39m c.z.p.s.impl.CustomerServiceImpl - Received command: com.zhigalko.producer.command.UpdateCustomerAddressCommand@5beffb03
2024-09-10 21:57:38 [http-nio-9001-exec-3] [34mINFO [0;39m c.z.core.service.KafkaProducer - Sending kafka message on topic UpdateCustomerAddressEventTopic
2024-09-10 21:57:38 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Kafka message successfully sent on topic UpdateCustomerAddressEventTopic and value {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32}
2024-09-10 21:57:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:57:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@60bccb9a
2024-09-10 21:58:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 32, changed: Moscow
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Group coordinator localhost:19092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Requesting disconnect from last known coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Client requested disconnect from node 2147483646
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Disconnecting from node 1 due to request timeout.
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Disconnecting from node 1 due to request timeout.
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Disconnecting from node 1 due to request timeout.
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Cancelled in-flight FETCH request with correlation id 581 due to node 1 being disconnected (elapsed time since creation: 55923ms, elapsed time since send: 55923ms, request timeout: 30000ms)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Cancelled in-flight FETCH request with correlation id 580 due to node 1 being disconnected (elapsed time since creation: 55923ms, elapsed time since send: 55923ms, request timeout: 30000ms)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Cancelled in-flight FETCH request with correlation id 582 due to node 1 being disconnected (elapsed time since creation: 55923ms, elapsed time since send: 55923ms, request timeout: 30000ms)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Disconnecting from node 2 due to request timeout.
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Disconnecting from node 2 due to request timeout.
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Disconnecting from node 2 due to request timeout.
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Cancelled in-flight FETCH request with correlation id 580 due to node 2 being disconnected (elapsed time since creation: 55923ms, elapsed time since send: 55923ms, request timeout: 30000ms)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Cancelled in-flight FETCH request with correlation id 581 due to node 2 being disconnected (elapsed time since creation: 55923ms, elapsed time since send: 55923ms, request timeout: 30000ms)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Cancelled in-flight FETCH request with correlation id 581 due to node 2 being disconnected (elapsed time since creation: 55923ms, elapsed time since send: 55923ms, request timeout: 30000ms)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Error sending fetch request (sessionId=190772355, epoch=260) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Error sending fetch request (sessionId=423866909, epoch=260) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Error sending fetch request (sessionId=1225099915, epoch=260) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Error sending fetch request (sessionId=1744612571, epoch=260) to node 2:
org.apache.kafka.common.errors.DisconnectException: null
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Error sending fetch request (sessionId=348366382, epoch=260) to node 2:
org.apache.kafka.common.errors.DisconnectException: null
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Error sending fetch request (sessionId=901238830, epoch=260) to node 2:
org.apache.kafka.common.errors.DisconnectException: null
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Group coordinator localhost:19092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Group coordinator localhost:19092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Group coordinator localhost:19092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Requesting disconnect from last known coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Requesting disconnect from last known coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Requesting disconnect from last known coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Client requested disconnect from node 2147483646
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Client requested disconnect from node 2147483646
2024-09-10 21:59:49 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Client requested disconnect from node 2147483646
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 7 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Group coordinator localhost:19092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Requesting disconnect from last known coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Attempt to heartbeat with Generation{generationId=90, memberId='consumer-customersConsumer-2-16cd60b7-5ff4-423b-beea-da4a6f8e556e', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Attempt to heartbeat with Generation{generationId=90, memberId='consumer-customersConsumer-4-3af79261-7cb8-458f-ae23-37e0e24195b8', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Lost previously assigned partitions UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Lost previously assigned partitions DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions lost: [DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions lost: [UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-4-692003a5-f540-444e-b9a4-d06881fbe58d
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-2-52af04ed-7349-4e83-b5f9-98e1558c066e
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 21:59:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:59:50 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Attempt to heartbeat with Generation{generationId=90, memberId='consumer-customersConsumer-1-3e5149b9-884f-4bc6-a3bd-913e104e1000', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2024-09-10 21:59:50 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2024-09-10 21:59:50 [kafka-coordinator-heartbeat-thread | customersConsumer] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Attempt to heartbeat with Generation{generationId=90, memberId='consumer-customersConsumer-3-c9336630-91de-40f2-b8b9-a5ccd5a83a27', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Lost previously assigned partitions CreateCustomerEventTopic-0, CreateCustomerEventTopic-1
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions lost: [CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-3-005e033f-fbf9-493a-aaa3-b5fe2750a094
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@6f213b07
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 33, changed: Moscow
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 7 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Lost previously assigned partitions UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions lost: [UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-1-7bd91a01-ac4c-4ed6-8e7d-938cbd97f051
2024-09-10 21:59:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] (Re-)joining group
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=92, memberId='consumer-customersConsumer-2-52af04ed-7349-4e83-b5f9-98e1558c066e', protocol='range'}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=92, memberId='consumer-customersConsumer-4-692003a5-f540-444e-b9a4-d06881fbe58d', protocol='range'}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=92, memberId='consumer-customersConsumer-1-7bd91a01-ac4c-4ed6-8e7d-938cbd97f051', protocol='range'}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=92, memberId='consumer-customersConsumer-3-005e033f-fbf9-493a-aaa3-b5fe2750a094', protocol='range'}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Finished assignment for group at generation 92: {consumer-customersConsumer-1-7bd91a01-ac4c-4ed6-8e7d-938cbd97f051=Assignment(partitions=[UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]), consumer-customersConsumer-3-005e033f-fbf9-493a-aaa3-b5fe2750a094=Assignment(partitions=[CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]), consumer-customersConsumer-2-52af04ed-7349-4e83-b5f9-98e1558c066e=Assignment(partitions=[DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]), consumer-customersConsumer-4-692003a5-f540-444e-b9a4-d06881fbe58d=Assignment(partitions=[UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1])}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=92, memberId='consumer-customersConsumer-4-692003a5-f540-444e-b9a4-d06881fbe58d', protocol='range'}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=92, memberId='consumer-customersConsumer-1-7bd91a01-ac4c-4ed6-8e7d-938cbd97f051', protocol='range'}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=92, memberId='consumer-customersConsumer-3-005e033f-fbf9-493a-aaa3-b5fe2750a094', protocol='range'}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=92, memberId='consumer-customersConsumer-2-52af04ed-7349-4e83-b5f9-98e1558c066e', protocol='range'}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1])
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1])
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[CreateCustomerEventTopic-0, CreateCustomerEventTopic-1])
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1])
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Adding newly assigned partitions: UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Adding newly assigned partitions: UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Adding newly assigned partitions: CreateCustomerEventTopic-0, CreateCustomerEventTopic-1
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Adding newly assigned partitions: DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerAddressEventTopic-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition DeleteCustomerEventTopic-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=6}}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CreateCustomerEventTopic-1 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerNameEventTopic-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerAddressEventTopic-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CreateCustomerEventTopic-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition DeleteCustomerEventTopic-1 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerNameEventTopic-1 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]
2024-09-10 21:59:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:59:54 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@69dd5bb8
2024-09-10 21:59:54 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 34, changed: Moscow
2024-09-10 21:59:54 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 7 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:59:54 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:59:54 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:59:54 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@5734241d
2024-09-10 21:59:54 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 35, changed: Moscow
2024-09-10 21:59:54 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 7 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:59:54 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@7771dff1
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 36, changed: Moscow
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 7 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@23574e26
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 37, changed: Moscow
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 7 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:59:55 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@b9c4dec
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 38, changed: Moscow
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 7 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at jdk.internal.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@38b2e9f2
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 39, changed: Moscow
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 7 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:59:56 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at jdk.internal.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:59:57 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:59:57 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@11b1fa4e
2024-09-10 21:59:57 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 40, changed: Moscow
2024-09-10 21:59:57 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Seeking to offset 7 for partition UpdateCustomerAddressEventTopic-0
2024-09-10 21:59:57 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at jdk.internal.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 21:59:57 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 7, CreateTime = 1725991058170, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "0084ebd0-1f8a-406b-9a8a-4975cef05f4e", "address": "Moscow", "timestamp": "2024-09-10T17:57:38.170054939Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 21:59:57 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@8c472ab
2024-09-10 21:59:57 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 41, changed: Moscow
2024-09-10 21:59:57 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [1;31mERROR[0;39m o.s.k.listener.DefaultErrorHandler - Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for UpdateCustomerAddressEventTopic-0@7
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerAddressAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerAddress(EventServiceImpl.java:103)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerAddressTopic(KafkaConsumer.java:36)
	at jdk.internal.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Revoke previously assigned partitions DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Revoke previously assigned partitions UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Revoke previously assigned partitions CreateCustomerEventTopic-0, CreateCustomerEventTopic-1
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Revoke previously assigned partitions UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Member consumer-customersConsumer-2-52af04ed-7349-4e83-b5f9-98e1558c066e sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Member consumer-customersConsumer-3-005e033f-fbf9-493a-aaa3-b5fe2750a094 sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Member consumer-customersConsumer-1-7bd91a01-ac4c-4ed6-8e7d-938cbd97f051 sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Member consumer-customersConsumer-4-692003a5-f540-444e-b9a4-d06881fbe58d sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-1 unregistered
2024-09-10 22:00:01 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-4 unregistered
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-3 unregistered
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-2 unregistered
2024-09-10 22:00:02 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:00:19 [main] [34mINFO [0;39m c.z.consumer.ConsumerApplication - Starting ConsumerApplication using Java 17.0.8 with PID 52568 (/home/anduser/dev/assessment/assessment-m2/consumer/target/classes started by anduser in /home/anduser/dev/assessment/assessment-m2)
2024-09-10 22:00:19 [main] [34mINFO [0;39m c.z.consumer.ConsumerApplication - No active profile set, falling back to 1 default profile: "default"
2024-09-10 22:00:19 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2024-09-10 22:00:19 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 30 ms. Found 2 MongoDB repository interfaces.
2024-09-10 22:00:19 [main] [34mINFO [0;39m org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.8.0-40-generic"}, "platform": "Java/Amazon.com Inc./17.0.8+7-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@358ab600, com.mongodb.Jep395RecordCodecProvider@e26af6, com.mongodb.KotlinCodecProvider@44065156]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
2024-09-10 22:00:19 [cluster-ClusterId{value='66e089333e8dfa092a73aebe', description='null'}-localhost:27017] [34mINFO [0;39m org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=9438795}
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 22:00:20 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:00:20 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991220155
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Subscribed to topic(s): UpdateCustomerAddressEventTopic
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 22:00:20 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:00:20 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991220168
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Subscribed to topic(s): DeleteCustomerEventTopic
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 22:00:20 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:00:20 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991220174
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Subscribed to topic(s): CreateCustomerEventTopic
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 22:00:20 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:00:20 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991220179
2024-09-10 22:00:20 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Subscribed to topic(s): UpdateCustomerNameEventTopic
2024-09-10 22:00:20 [main] [34mINFO [0;39m c.z.consumer.ConsumerApplication - Started ConsumerApplication in 1.095 seconds (process running for 1.573)
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-1-1b16b7b8-1ce3-465f-8a1d-9cec81b37a4b
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-4-6c5c21f1-7bba-4754-ac72-a1b65b40ad5a
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-3-97b1c044-8746-437c-a939-a7462dd613b8
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-2-655ea669-0178-4f6d-8c8f-0dac1cbc4951
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:00:20 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=94, memberId='consumer-customersConsumer-2-655ea669-0178-4f6d-8c8f-0dac1cbc4951', protocol='range'}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=94, memberId='consumer-customersConsumer-1-1b16b7b8-1ce3-465f-8a1d-9cec81b37a4b', protocol='range'}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=94, memberId='consumer-customersConsumer-4-6c5c21f1-7bba-4754-ac72-a1b65b40ad5a', protocol='range'}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=94, memberId='consumer-customersConsumer-3-97b1c044-8746-437c-a939-a7462dd613b8', protocol='range'}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Finished assignment for group at generation 94: {consumer-customersConsumer-2-655ea669-0178-4f6d-8c8f-0dac1cbc4951=Assignment(partitions=[DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]), consumer-customersConsumer-1-1b16b7b8-1ce3-465f-8a1d-9cec81b37a4b=Assignment(partitions=[UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]), consumer-customersConsumer-4-6c5c21f1-7bba-4754-ac72-a1b65b40ad5a=Assignment(partitions=[UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]), consumer-customersConsumer-3-97b1c044-8746-437c-a939-a7462dd613b8=Assignment(partitions=[CreateCustomerEventTopic-0, CreateCustomerEventTopic-1])}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=94, memberId='consumer-customersConsumer-1-1b16b7b8-1ce3-465f-8a1d-9cec81b37a4b', protocol='range'}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=94, memberId='consumer-customersConsumer-3-97b1c044-8746-437c-a939-a7462dd613b8', protocol='range'}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=94, memberId='consumer-customersConsumer-4-6c5c21f1-7bba-4754-ac72-a1b65b40ad5a', protocol='range'}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=94, memberId='consumer-customersConsumer-2-655ea669-0178-4f6d-8c8f-0dac1cbc4951', protocol='range'}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1])
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1])
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1])
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[CreateCustomerEventTopic-0, CreateCustomerEventTopic-1])
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Adding newly assigned partitions: CreateCustomerEventTopic-0, CreateCustomerEventTopic-1
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Adding newly assigned partitions: DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Adding newly assigned partitions: UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Adding newly assigned partitions: UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerAddressEventTopic-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerNameEventTopic-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition DeleteCustomerEventTopic-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=6}}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CreateCustomerEventTopic-1 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerNameEventTopic-1 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition DeleteCustomerEventTopic-1 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerAddressEventTopic-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CreateCustomerEventTopic-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]
2024-09-10 22:00:23 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]
2024-09-10 22:00:41 [http-nio-9001-exec-5] [34mINFO [0;39m c.z.p.s.impl.CustomerServiceImpl - Received command: com.zhigalko.producer.command.UpdateCustomerNameCommand@6623e55c
2024-09-10 22:00:41 [http-nio-9001-exec-5] [34mINFO [0;39m c.z.core.service.KafkaProducer - Sending kafka message on topic UpdateCustomerNameEventTopic
2024-09-10 22:00:41 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Kafka message successfully sent on topic UpdateCustomerNameEventTopic and value {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32}
2024-09-10 22:00:41 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:41 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@7c36246e
2024-09-10 22:00:41 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 42, changed: Evgeniy
2024-09-10 22:00:41 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerNameEventTopic-1
2024-09-10 22:00:41 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@256c91c8
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 43, changed: Evgeniy
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerNameEventTopic-1
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@4e6d2edd
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 44, changed: Evgeniy
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerNameEventTopic-1
2024-09-10 22:00:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@4efc11e3
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 45, changed: Evgeniy
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerNameEventTopic-1
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@45d973b5
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 46, changed: Evgeniy
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerNameEventTopic-1
2024-09-10 22:00:43 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@54efc912
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 47, changed: Evgeniy
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerNameEventTopic-1
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@3b8793fc
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 48, changed: Evgeniy
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerNameEventTopic-1
2024-09-10 22:00:44 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@7af7b082
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 49, changed: Evgeniy
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerNameEventTopic-1
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@36981712
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 50, changed: Evgeniy
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Seeking to offset 6 for partition UpdateCustomerNameEventTopic-1
2024-09-10 22:00:45 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.l.KafkaMessageListenerContainer - Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:227)
	at org.springframework.kafka.listener.DefaultErrorHandler.handleRemaining(DefaultErrorHandler.java:168)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2836)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2713)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	... 11 common frames omitted
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:00:46 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 6, CreateTime = 1725991241546, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "a0315d46-b803-42ce-96d0-5e683d0ba057", "name": "Evgeniy", "timestamp": "2024-09-10T18:00:41.543030443Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:00:46 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@6ca8c34b
2024-09-10 22:00:46 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 51, changed: Evgeniy
2024-09-10 22:00:46 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [1;31mERROR[0;39m o.s.k.listener.DefaultErrorHandler - Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for UpdateCustomerNameEventTopic-1@6
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, com.zhigalko.core.schema.UpdateCustomerNameAvroEvent>)' threw exception
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2869)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2814)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2778)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$53(KafkaMessageListenerContainer.java:2701)
	at io.micrometer.observation.Observation.observe(Observation.java:565)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2699)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2541)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2430)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2085)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1461)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1426)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1296)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:833)
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:435)
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
Caused by: java.lang.NumberFormatException: For input string: "5ca6779f-e65d-456c-939d-3ad9c55e580e"
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Long.parseLong(Long.java:711)
	at java.base/java.lang.Long.parseLong(Long.java:836)
	at com.zhigalko.consumer.mapper.CustomerMapperImpl.toCustomer(CustomerMapperImpl.java:29)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.sendUpdateCustomerEvent(EventServiceImpl.java:136)
	at com.zhigalko.consumer.service.impl.EventServiceImpl.updateCustomerName(EventServiceImpl.java:86)
	at com.zhigalko.consumer.listener.KafkaConsumer.listenUpdateCustomerNameTopic(KafkaConsumer.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:70)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:420)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:384)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2800)
	... 13 common frames omitted
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Revoke previously assigned partitions UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Revoke previously assigned partitions CreateCustomerEventTopic-0, CreateCustomerEventTopic-1
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Revoke previously assigned partitions UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Revoke previously assigned partitions DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Member consumer-customersConsumer-1-1b16b7b8-1ce3-465f-8a1d-9cec81b37a4b sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Member consumer-customersConsumer-2-655ea669-0178-4f6d-8c8f-0dac1cbc4951 sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Member consumer-customersConsumer-4-6c5c21f1-7bba-4754-ac72-a1b65b40ad5a sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Member consumer-customersConsumer-3-97b1c044-8746-437c-a939-a7462dd613b8 sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-1 unregistered
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-3 unregistered
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-2 unregistered
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-4 unregistered
2024-09-10 22:01:42 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:02:06 [main] [34mINFO [0;39m c.z.consumer.ConsumerApplication - Starting ConsumerApplication using Java 17.0.8 with PID 53115 (/home/anduser/dev/assessment/assessment-m2/consumer/target/classes started by anduser in /home/anduser/dev/assessment/assessment-m2)
2024-09-10 22:02:06 [main] [34mINFO [0;39m c.z.consumer.ConsumerApplication - No active profile set, falling back to 1 default profile: "default"
2024-09-10 22:02:06 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2024-09-10 22:02:06 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 26 ms. Found 2 MongoDB repository interfaces.
2024-09-10 22:02:06 [main] [34mINFO [0;39m org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.8.0-40-generic"}, "platform": "Java/Amazon.com Inc./17.0.8+7-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='admin', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@20f6f88c, com.mongodb.Jep395RecordCodecProvider@4277127c, com.mongodb.KotlinCodecProvider@4c7e978c]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
2024-09-10 22:02:06 [cluster-ClusterId{value='66e0899e04dbfb038ddaf7e2', description='null'}-localhost:27017] [34mINFO [0;39m org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=10240538}
2024-09-10 22:02:06 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 22:02:06 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 22:02:07 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:02:07 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991327123
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Subscribed to topic(s): UpdateCustomerAddressEventTopic
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 22:02:07 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:02:07 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991327137
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Subscribed to topic(s): DeleteCustomerEventTopic
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 22:02:07 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:02:07 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991327143
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Subscribed to topic(s): CreateCustomerEventTopic
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-customersConsumer-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = customersConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 22:02:07 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:02:07 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991327148
2024-09-10 22:02:07 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Subscribed to topic(s): UpdateCustomerNameEventTopic
2024-09-10 22:02:07 [main] [34mINFO [0;39m c.z.consumer.ConsumerApplication - Started ConsumerApplication in 1.239 seconds (process running for 1.858)
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Discovered group coordinator localhost:19092 (id: 2147483646 rack: null)
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-2-17591b10-2bb4-443a-b807-578ccdd8f4ff
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-1-17483505-be54-4f70-bf11-eaf11dd4b53b
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-4-ec1cf108-cba6-491a-9012-519c63598be5
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: need to re-join with the given member-id: consumer-customersConsumer-3-90d17d61-4778-4f82-97f3-57f84df6e79c
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:02:07 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] (Re-)joining group
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=96, memberId='consumer-customersConsumer-4-ec1cf108-cba6-491a-9012-519c63598be5', protocol='range'}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=96, memberId='consumer-customersConsumer-3-90d17d61-4778-4f82-97f3-57f84df6e79c', protocol='range'}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=96, memberId='consumer-customersConsumer-1-17483505-be54-4f70-bf11-eaf11dd4b53b', protocol='range'}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Successfully joined group with generation Generation{generationId=96, memberId='consumer-customersConsumer-2-17591b10-2bb4-443a-b807-578ccdd8f4ff', protocol='range'}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Finished assignment for group at generation 96: {consumer-customersConsumer-3-90d17d61-4778-4f82-97f3-57f84df6e79c=Assignment(partitions=[CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]), consumer-customersConsumer-4-ec1cf108-cba6-491a-9012-519c63598be5=Assignment(partitions=[UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]), consumer-customersConsumer-1-17483505-be54-4f70-bf11-eaf11dd4b53b=Assignment(partitions=[UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]), consumer-customersConsumer-2-17591b10-2bb4-443a-b807-578ccdd8f4ff=Assignment(partitions=[DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1])}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=96, memberId='consumer-customersConsumer-2-17591b10-2bb4-443a-b807-578ccdd8f4ff', protocol='range'}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=96, memberId='consumer-customersConsumer-4-ec1cf108-cba6-491a-9012-519c63598be5', protocol='range'}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=96, memberId='consumer-customersConsumer-3-90d17d61-4778-4f82-97f3-57f84df6e79c', protocol='range'}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Successfully synced group in generation Generation{generationId=96, memberId='consumer-customersConsumer-1-17483505-be54-4f70-bf11-eaf11dd4b53b', protocol='range'}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1])
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[CreateCustomerEventTopic-0, CreateCustomerEventTopic-1])
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1])
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Notifying assignor about the new Assignment(partitions=[UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1])
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Adding newly assigned partitions: DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Adding newly assigned partitions: CreateCustomerEventTopic-0, CreateCustomerEventTopic-1
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Adding newly assigned partitions: UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Adding newly assigned partitions: UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerNameEventTopic-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CreateCustomerEventTopic-1 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerAddressEventTopic-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition DeleteCustomerEventTopic-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=6}}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerNameEventTopic-1 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition CreateCustomerEventTopic-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition UpdateCustomerAddressEventTopic-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 2 rack: null)], epoch=8}}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition DeleteCustomerEventTopic-1 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:19092 (id: 1 rack: null)], epoch=2}}
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]
2024-09-10 22:02:10 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions assigned: [DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]
2024-09-10 22:02:15 [http-nio-9001-exec-9] [34mINFO [0;39m c.z.p.s.impl.CustomerServiceImpl - Received command: com.zhigalko.producer.command.UpdateCustomerNameCommand@37ecbab4
2024-09-10 22:02:15 [http-nio-9001-exec-9] [34mINFO [0;39m c.z.core.service.KafkaProducer - Sending kafka message on topic UpdateCustomerNameEventTopic
2024-09-10 22:02:15 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Kafka message successfully sent on topic UpdateCustomerNameEventTopic and value {"id": "17f92984-087a-4938-89f4-fcb45f74328f", "name": "Evgeniy", "timestamp": "2024-09-10T18:02:15.703045956Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32}
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerNameEventTopic, partition = 1, leaderEpoch = 2, offset = 7, CreateTime = 1725991335703, serialized key size = -1, serialized value size = 106, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "17f92984-087a-4938-89f4-fcb45f74328f", "name": "Evgeniy", "timestamp": "2024-09-10T18:02:15.703045956Z", "eventType": "UpdateCustomerNameEvent", "aggregateId": 32})
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerNameEvent, payload: com.zhigalko.core.event.UpdateCustomerNameEvent@3a543bbf
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 52, changed: Evgeniy
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [http://localhost:19092, http://localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-service-producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://127.0.0.1:8081]
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.clients.producer.KafkaProducer - [Producer clientId=consumer-service-producer-1] Instantiated an idempotent producer.
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.producer.ProducerConfig - These configurations '[schema.registry.url]' were supplied but are not used yet.
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1725991335967
2024-09-10 22:02:15 [kafka-producer-network-thread | consumer-service-producer-1] [34mINFO [0;39m org.apache.kafka.clients.Metadata - [Producer clientId=consumer-service-producer-1] Cluster ID: FqcP9J1MQ5a2psFQkE3dfA
2024-09-10 22:02:15 [kafka-producer-network-thread | consumer-service-producer-1] [34mINFO [0;39m o.a.k.c.p.i.TransactionManager - [Producer clientId=consumer-service-producer-1] ProducerId set to 12002 with epoch 0
2024-09-10 22:02:15 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Sending kafka message on topic CustomerViewEventTopic
2024-09-10 22:02:15 [kafka-producer-network-thread | consumer-service-producer-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Kafka message successfully sent on topic CustomerViewEventTopic and value {"id": "44e47ea6-7bca-4d3a-8ad4-bfd619170d84", "name": "Evgeniy", "address": "Moscow", "timestamp": "2024-09-10T18:02:15.944434367Z", "eventType": "UpdateCustomerNameViewEvent", "aggregateId": 32, "version": 52}
2024-09-10 22:02:16 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m c.z.producer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = CustomerViewEventTopic, partition = 0, leaderEpoch = 2, offset = 35, CreateTime = 1725991335970, serialized key size = -1, serialized value size = 118, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "44e47ea6-7bca-4d3a-8ad4-bfd619170d84", "name": "Evgeniy", "address": "Moscow", "timestamp": "2024-09-10T18:02:15.944434367Z", "eventType": "UpdateCustomerNameViewEvent", "aggregateId": 32, "version": 52})
2024-09-10 22:02:16 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m c.z.p.projector.CustomerProjector - Updated customer projection for: 32
2024-09-10 22:02:43 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m c.z.p.s.i.CustomerQueryServiceImpl - Customer projection was stored: id - 32, name - Evgeniy
2024-09-10 22:02:46 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m c.z.p.s.i.CustomerQueryServiceImpl - Saved in cached value: CustomerProjection[id=32, name=Evgeniy, address=Moscow]
2024-09-10 22:03:08 [http-nio-9001-exec-10] [34mINFO [0;39m c.z.p.s.impl.CustomerServiceImpl - Received command: com.zhigalko.producer.command.UpdateCustomerAddressCommand@eb547d8
2024-09-10 22:03:08 [http-nio-9001-exec-10] [34mINFO [0;39m c.z.core.service.KafkaProducer - Sending kafka message on topic UpdateCustomerAddressEventTopic
2024-09-10 22:03:08 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Kafka message successfully sent on topic UpdateCustomerAddressEventTopic and value {"id": "3f1cae54-c1bd-4b15-b465-772339721de6", "address": "London", "timestamp": "2024-09-10T18:03:08.491771351Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32}
2024-09-10 22:03:08 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.consumer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = UpdateCustomerAddressEventTopic, partition = 0, leaderEpoch = 8, offset = 8, CreateTime = 1725991388491, serialized key size = -1, serialized value size = 108, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "3f1cae54-c1bd-4b15-b465-772339721de6", "address": "London", "timestamp": "2024-09-10T18:03:08.491771351Z", "eventType": "UpdateCustomerAddressEvent", "aggregateId": 32})
2024-09-10 22:03:08 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Event was saved: class: class com.zhigalko.core.event.UpdateCustomerAddressEvent, payload: com.zhigalko.core.event.UpdateCustomerAddressEvent@17d76fc7
2024-09-10 22:03:08 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.c.service.impl.EventServiceImpl - Snapshot was updated for id: 32, version: 53, changed: London
2024-09-10 22:03:08 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Sending kafka message on topic CustomerViewEventTopic
2024-09-10 22:03:08 [kafka-producer-network-thread | consumer-service-producer-1] [34mINFO [0;39m c.z.core.service.KafkaProducer - Kafka message successfully sent on topic CustomerViewEventTopic and value {"id": "82e7e5b0-d939-48e9-9bb3-01bbcbd3aacc", "name": "Evgeniy", "address": "London", "timestamp": "2024-09-10T18:03:08.511486119Z", "eventType": "UpdateCustomerAddressViewEvent", "aggregateId": 32, "version": 53}
2024-09-10 22:03:08 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m c.z.producer.listener.KafkaConsumer - Received event: ConsumerRecord(topic = CustomerViewEventTopic, partition = 0, leaderEpoch = 2, offset = 36, CreateTime = 1725991388511, serialized key size = -1, serialized value size = 121, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"id": "82e7e5b0-d939-48e9-9bb3-01bbcbd3aacc", "name": "Evgeniy", "address": "London", "timestamp": "2024-09-10T18:03:08.511486119Z", "eventType": "UpdateCustomerAddressViewEvent", "aggregateId": 32, "version": 53})
2024-09-10 22:03:08 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m c.z.p.projector.CustomerProjector - Updated customer projection for: 32
2024-09-10 22:03:11 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m c.z.p.s.i.CustomerQueryServiceImpl - Customer projection was stored: id - 32, name - Evgeniy
2024-09-10 22:03:11 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m c.z.p.s.i.CustomerQueryServiceImpl - Saved in cached value: CustomerProjection[id=32, name=Evgeniy, address=London]
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Node -2 disconnected.
2024-09-10 22:04:32 [kafka-coordinator-heartbeat-thread | customerViewConsumer] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Node -1 disconnected.
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Revoke previously assigned partitions CreateCustomerEventTopic-0, CreateCustomerEventTopic-1
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Revoke previously assigned partitions UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Revoke previously assigned partitions UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Revoke previously assigned partitions DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [CreateCustomerEventTopic-0, CreateCustomerEventTopic-1]
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [UpdateCustomerAddressEventTopic-0, UpdateCustomerAddressEventTopic-1]
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [DeleteCustomerEventTopic-0, DeleteCustomerEventTopic-1]
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: partitions revoked: [UpdateCustomerNameEventTopic-0, UpdateCustomerNameEventTopic-1]
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Member consumer-customersConsumer-3-90d17d61-4778-4f82-97f3-57f84df6e79c sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Member consumer-customersConsumer-1-17483505-be54-4f70-bf11-eaf11dd4b53b sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Member consumer-customersConsumer-4-ec1cf108-cba6-491a-9012-519c63598be5 sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Member consumer-customersConsumer-2-17591b10-2bb4-443a-b807-578ccdd8f4ff sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-4, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-3, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-2, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customersConsumer-1, groupId=customersConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-1 unregistered
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-2 unregistered
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-3 unregistered
2024-09-10 22:04:32 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:04:33 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:04:33 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:04:33 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:04:33 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:04:33 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customersConsumer-4 unregistered
2024-09-10 22:04:33 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customersConsumer: Consumer stopped
2024-09-10 22:04:33 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.k.clients.producer.KafkaProducer - [Producer clientId=consumer-service-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-09-10 22:04:33 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:04:33 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:04:33 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:04:33 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:04:33 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for consumer-service-producer-1 unregistered
2024-09-10 22:05:05 [http-nio-9001-exec-3] [34mINFO [0;39m o.s.d.m.core.convert.QueryMapper - Could not map 'Customer.id'; Maybe a fragment in 'Long' is considered a simple type; Mapper continues with id
2024-09-10 22:05:05 [http-nio-9001-exec-3] [34mINFO [0;39m c.z.p.s.i.CustomerQueryServiceImpl - Saved in cached value: CustomerProjection[id=32, name=Evgeniy, address=London]
2024-09-10 22:06:08 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-service-producer-1] Node -2 disconnected.
2024-09-10 22:06:08 [kafka-producer-network-thread | producer-service-producer-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-service-producer-1] Node -1 disconnected.
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Revoke previously assigned partitions CustomerViewEventTopic-0, CustomerViewEventTopic-1
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customerViewConsumer: partitions revoked: [CustomerViewEventTopic-0, CustomerViewEventTopic-1]
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Member consumer-customerViewConsumer-1-f24fe5d9-9399-4cc5-a556-4d696eaa60ea sending LeaveGroup request to coordinator localhost:19092 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-customerViewConsumer-1, groupId=customerViewConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-customerViewConsumer-1 unregistered
2024-09-10 22:15:01 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - customerViewConsumer: Consumer stopped
2024-09-10 22:15:01 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-service-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-09-10 22:15:01 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-10 22:15:01 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-10 22:15:01 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-10 22:15:01 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-10 22:15:01 [SpringApplicationShutdownHook] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-service-producer-1 unregistered
