2024-09-15 22:28:47 [main] [34mINFO [0;39m o.s.t.c.s.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [com.zhigalko.consumer.integration.repository.SnapshotRepositoryIT]: SnapshotRepositoryIT does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-09-15 22:28:47 [main] [34mINFO [0;39m o.s.b.t.c.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration com.zhigalko.consumer.ConsumerApplication for test class com.zhigalko.consumer.integration.repository.SnapshotRepositoryIT
2024-09-15 22:28:47 [main] [34mINFO [0;39m o.testcontainers.images.PullPolicy - Image pull policy will be performed by: DefaultPullPolicy()
2024-09-15 22:28:47 [main] [34mINFO [0;39m o.t.utility.ImageNameSubstitutor - Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')
2024-09-15 22:28:47 [main] [34mINFO [0;39m o.t.d.DockerClientProviderStrategy - Loaded org.testcontainers.dockerclient.UnixSocketClientProviderStrategy from ~/.testcontainers.properties, will try it first
2024-09-15 22:28:47 [main] [34mINFO [0;39m o.t.d.DockerClientProviderStrategy - Found Docker environment with local Unix socket (unix:///var/run/docker.sock)
2024-09-15 22:28:47 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - Docker host IP address is localhost
2024-09-15 22:28:47 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - Connected to docker: 
  Server Version: 26.1.0
  API Version: 1.45
  Operating System: Ubuntu 22.04.4 LTS
  Total Memory: 15676 MB
2024-09-15 22:28:47 [main] [34mINFO [0;39m tc.testcontainers/ryuk:0.7.0 - Creating container for image: testcontainers/ryuk:0.7.0
2024-09-15 22:28:48 [main] [34mINFO [0;39m tc.testcontainers/ryuk:0.7.0 - Container testcontainers/ryuk:0.7.0 is starting: f94fd9760917ec415a01fd8258315f1bde8d53e244d8b1db42be4bca5be640b0
2024-09-15 22:28:48 [main] [34mINFO [0;39m tc.testcontainers/ryuk:0.7.0 - Container testcontainers/ryuk:0.7.0 started in PT0.743808173S
2024-09-15 22:28:48 [main] [34mINFO [0;39m o.t.utility.RyukResourceReaper - Ryuk started - will monitor and terminate Testcontainers containers on JVM exit
2024-09-15 22:28:48 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - Checking the system...
2024-09-15 22:28:48 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - âœ”ï¸Ž Docker server version should be at least 1.6.0
2024-09-15 22:28:48 [main] [34mINFO [0;39m tc.mongo:latest - Creating container for image: mongo:latest
2024-09-15 22:28:48 [main] [34mINFO [0;39m tc.mongo:latest - Container mongo:latest is starting: ecda58479839260252aa9b82072543560c7c8b4ece178b0a829beecff5a84677
2024-09-15 22:28:49 [main] [34mINFO [0;39m tc.mongo:latest - Container mongo:latest started in PT0.699260335S
2024-09-15 22:28:50 [main] [34mINFO [0;39m c.z.c.i.r.SnapshotRepositoryIT - Starting SnapshotRepositoryIT using Java 17.0.8 with PID 549402 (started by anduser in /home/anduser/dev/assessment/assessment-m2/consumer)
2024-09-15 22:28:50 [main] [34mINFO [0;39m c.z.c.i.r.SnapshotRepositoryIT - No active profile set, falling back to 1 default profile: "default"
2024-09-15 22:28:50 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2024-09-15 22:28:50 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 37 ms. Found 2 MongoDB repository interfaces.
2024-09-15 22:28:50 [main] [34mINFO [0;39m org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.8.0-40-generic"}, "platform": "Java/Amazon.com Inc./17.0.8+7-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@61808ecd, com.mongodb.Jep395RecordCodecProvider@7f1f60a0, com.mongodb.KotlinCodecProvider@77ea806f]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:33852], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
2024-09-15 22:28:50 [cluster-ClusterId{value='66e72762e2c2000bf8c8fd90', description='null'}-localhost:33852] [34mINFO [0;39m org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:33852, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=13189781, setName='docker-rs', canonicalAddress=ecda58479839:27017, hosts=[ecda58479839:27017], passives=[], arbiters=[], primary='ecda58479839:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, topologyVersion=TopologyVersion{processId=66e7276085fb906046b12549, counter=6}, lastWriteDate=Sun Sep 15 22:28:49 GET 2024, lastUpdateTimeNanos=33247817990154}
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:28:51 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:28:51 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726424931352
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Subscribed to topic(s): UpdateCustomerAddressEventTopic
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:28:51 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:28:51 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726424931371
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Subscribed to topic(s): DeleteCustomerEventTopic
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:28:51 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:28:51 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726424931380
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Subscribed to topic(s): CreateCustomerEventTopic
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:28:51 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:28:51 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726424931390
2024-09-15 22:28:51 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Subscribed to topic(s): UpdateCustomerNameEventTopic
2024-09-15 22:28:51 [main] [34mINFO [0;39m c.z.c.i.r.SnapshotRepositoryIT - Started SnapshotRepositoryIT in 1.364 seconds (process running for 4.656)
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:28:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:28:52 [cluster-ClusterId{value='66e72762e2c2000bf8c8fd90', description='null'}-localhost:33852] [34mINFO [0;39m org.mongodb.driver.cluster - Exception in monitor thread while connecting to server localhost:33852
com.mongodb.MongoSocketReadException: Prematurely reached end of stream
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:178)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:196)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:716)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:580)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:428)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:381)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:221)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:153)
	at java.base/java.lang.Thread.run(Thread.java:833)
2024-09-15 22:28:52 [cluster-ClusterId{value='66e72762e2c2000bf8c8fd90', description='null'}-localhost:33852] [34mINFO [0;39m org.mongodb.driver.cluster - Exception in monitor thread while connecting to server localhost:33852
com.mongodb.MongoSocketReadException: Exception receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:707)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:583)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:428)
	at com.mongodb.internal.connection.InternalStreamConnection.sendAndReceive(InternalStreamConnection.java:354)
	at com.mongodb.internal.connection.CommandHelper.sendAndReceive(CommandHelper.java:92)
	at com.mongodb.internal.connection.CommandHelper.executeCommand(CommandHelper.java:48)
	at com.mongodb.internal.connection.InternalStreamConnectionInitializer.initializeConnectionDescription(InternalStreamConnectionInitializer.java:130)
	at com.mongodb.internal.connection.InternalStreamConnectionInitializer.startHandshake(InternalStreamConnectionInitializer.java:78)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:203)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:193)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:153)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:328)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:176)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:196)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:716)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:580)
	... 10 common frames omitted
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-2 unregistered
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-1 unregistered
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-4 unregistered
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-3 unregistered
2024-09-15 22:28:52 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:34:44 [main] [34mINFO [0;39m o.testcontainers.images.PullPolicy - Image pull policy will be performed by: DefaultPullPolicy()
2024-09-15 22:34:44 [main] [34mINFO [0;39m o.t.utility.ImageNameSubstitutor - Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')
2024-09-15 22:34:45 [main] [34mINFO [0;39m o.s.t.c.s.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [com.zhigalko.consumer.integration.repository.SnapshotRepositoryIT]: SnapshotRepositoryIT does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-09-15 22:34:45 [main] [34mINFO [0;39m o.s.b.t.c.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration com.zhigalko.consumer.ConsumerApplication for test class com.zhigalko.consumer.integration.repository.SnapshotRepositoryIT
2024-09-15 22:34:45 [main] [34mINFO [0;39m o.t.d.DockerClientProviderStrategy - Loaded org.testcontainers.dockerclient.UnixSocketClientProviderStrategy from ~/.testcontainers.properties, will try it first
2024-09-15 22:34:45 [main] [34mINFO [0;39m o.t.d.DockerClientProviderStrategy - Found Docker environment with local Unix socket (unix:///var/run/docker.sock)
2024-09-15 22:34:45 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - Docker host IP address is localhost
2024-09-15 22:34:45 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - Connected to docker: 
  Server Version: 26.1.0
  API Version: 1.45
  Operating System: Ubuntu 22.04.4 LTS
  Total Memory: 15676 MB
2024-09-15 22:34:45 [main] [34mINFO [0;39m tc.testcontainers/ryuk:0.7.0 - Creating container for image: testcontainers/ryuk:0.7.0
2024-09-15 22:34:45 [main] [34mINFO [0;39m tc.testcontainers/ryuk:0.7.0 - Container testcontainers/ryuk:0.7.0 is starting: 7c9cdafa7dbb54570f5ecc27e944c33e6555d0cc0536f45ea6ab3d8f096e8e03
2024-09-15 22:34:46 [main] [34mINFO [0;39m tc.testcontainers/ryuk:0.7.0 - Container testcontainers/ryuk:0.7.0 started in PT0.735995078S
2024-09-15 22:34:46 [main] [34mINFO [0;39m o.t.utility.RyukResourceReaper - Ryuk started - will monitor and terminate Testcontainers containers on JVM exit
2024-09-15 22:34:46 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - Checking the system...
2024-09-15 22:34:46 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - âœ”ï¸Ž Docker server version should be at least 1.6.0
2024-09-15 22:34:46 [main] [34mINFO [0;39m tc.mongo:latest - Creating container for image: mongo:latest
2024-09-15 22:34:46 [main] [34mINFO [0;39m tc.mongo:latest - Container mongo:latest is starting: 984e372fc8f96ca26d9101928b8e1b76a2ed6a29ad06199df8763269a6d24ba2
2024-09-15 22:34:46 [main] [34mINFO [0;39m tc.mongo:latest - Container mongo:latest started in PT0.695550203S
2024-09-15 22:34:47 [main] [34mINFO [0;39m c.z.c.i.r.SnapshotRepositoryIT - Starting SnapshotRepositoryIT using Java 17.0.8 with PID 551563 (started by anduser in /home/anduser/dev/assessment/assessment-m2/consumer)
2024-09-15 22:34:47 [main] [34mINFO [0;39m c.z.c.i.r.SnapshotRepositoryIT - No active profile set, falling back to 1 default profile: "default"
2024-09-15 22:34:48 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2024-09-15 22:34:48 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 37 ms. Found 2 MongoDB repository interfaces.
2024-09-15 22:34:48 [main] [34mINFO [0;39m org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.8.0-40-generic"}, "platform": "Java/Amazon.com Inc./17.0.8+7-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@4c56644f, com.mongodb.Jep395RecordCodecProvider@589dfa6f, com.mongodb.KotlinCodecProvider@43588265]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:33856], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
2024-09-15 22:34:48 [cluster-ClusterId{value='66e728c89bf2084020a95266', description='null'}-localhost:33856] [34mINFO [0;39m org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:33856, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=20581464, setName='docker-rs', canonicalAddress=984e372fc8f9:27017, hosts=[984e372fc8f9:27017], passives=[], arbiters=[], primary='984e372fc8f9:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, topologyVersion=TopologyVersion{processId=66e728c6eb92f16eb95534c1, counter=6}, lastWriteDate=Sun Sep 15 22:34:47 GET 2024, lastUpdateTimeNanos=33605512315511}
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:34:49 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:34:49 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726425289330
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Subscribed to topic(s): UpdateCustomerAddressEventTopic
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:34:49 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:34:49 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726425289366
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Subscribed to topic(s): DeleteCustomerEventTopic
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:34:49 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:34:49 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726425289382
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Subscribed to topic(s): CreateCustomerEventTopic
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:34:49 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:34:49 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726425289389
2024-09-15 22:34:49 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Subscribed to topic(s): UpdateCustomerNameEventTopic
2024-09-15 22:34:49 [main] [34mINFO [0;39m c.z.c.i.r.SnapshotRepositoryIT - Started SnapshotRepositoryIT in 1.754 seconds (process running for 5.298)
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:49 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:34:50 [cluster-ClusterId{value='66e728c89bf2084020a95266', description='null'}-localhost:33856] [34mINFO [0;39m org.mongodb.driver.cluster - Exception in monitor thread while connecting to server localhost:33856
com.mongodb.MongoSocketReadException: Prematurely reached end of stream
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:178)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:196)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:716)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:580)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:428)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:381)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:221)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:153)
	at java.base/java.lang.Thread.run(Thread.java:833)
2024-09-15 22:34:50 [cluster-ClusterId{value='66e728c89bf2084020a95266', description='null'}-localhost:33856] [34mINFO [0;39m org.mongodb.driver.cluster - Exception in monitor thread while connecting to server localhost:33856
com.mongodb.MongoSocketReadException: Exception receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:707)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:583)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:428)
	at com.mongodb.internal.connection.InternalStreamConnection.sendAndReceive(InternalStreamConnection.java:354)
	at com.mongodb.internal.connection.CommandHelper.sendAndReceive(CommandHelper.java:92)
	at com.mongodb.internal.connection.CommandHelper.executeCommand(CommandHelper.java:48)
	at com.mongodb.internal.connection.InternalStreamConnectionInitializer.initializeConnectionDescription(InternalStreamConnectionInitializer.java:130)
	at com.mongodb.internal.connection.InternalStreamConnectionInitializer.startHandshake(InternalStreamConnectionInitializer.java:78)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:203)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:193)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:153)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:328)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:176)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:196)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:716)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:580)
	... 10 common frames omitted
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-4 unregistered
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-2 unregistered
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-3 unregistered
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-1 unregistered
2024-09-15 22:34:50 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:36:01 [main] [34mINFO [0;39m o.s.t.c.s.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [com.zhigalko.consumer.integration.repository.SnapshotRepositoryIT]: SnapshotRepositoryIT does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-09-15 22:36:01 [main] [34mINFO [0;39m o.s.b.t.c.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration com.zhigalko.consumer.ConsumerApplication for test class com.zhigalko.consumer.integration.repository.SnapshotRepositoryIT
2024-09-15 22:36:01 [main] [34mINFO [0;39m o.testcontainers.images.PullPolicy - Image pull policy will be performed by: DefaultPullPolicy()
2024-09-15 22:36:01 [main] [34mINFO [0;39m o.t.utility.ImageNameSubstitutor - Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')
2024-09-15 22:36:01 [main] [34mINFO [0;39m o.t.d.DockerClientProviderStrategy - Loaded org.testcontainers.dockerclient.UnixSocketClientProviderStrategy from ~/.testcontainers.properties, will try it first
2024-09-15 22:36:01 [main] [34mINFO [0;39m o.t.d.DockerClientProviderStrategy - Found Docker environment with local Unix socket (unix:///var/run/docker.sock)
2024-09-15 22:36:01 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - Docker host IP address is localhost
2024-09-15 22:36:01 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - Connected to docker: 
  Server Version: 26.1.0
  API Version: 1.45
  Operating System: Ubuntu 22.04.4 LTS
  Total Memory: 15676 MB
2024-09-15 22:36:01 [main] [34mINFO [0;39m tc.testcontainers/ryuk:0.7.0 - Creating container for image: testcontainers/ryuk:0.7.0
2024-09-15 22:36:02 [main] [34mINFO [0;39m tc.testcontainers/ryuk:0.7.0 - Container testcontainers/ryuk:0.7.0 is starting: 258ee5d769afdc95f6b251de49d2197c4e3a9414e311ff172c1c9597b7656daa
2024-09-15 22:36:02 [main] [34mINFO [0;39m tc.testcontainers/ryuk:0.7.0 - Container testcontainers/ryuk:0.7.0 started in PT0.822889473S
2024-09-15 22:36:02 [main] [34mINFO [0;39m o.t.utility.RyukResourceReaper - Ryuk started - will monitor and terminate Testcontainers containers on JVM exit
2024-09-15 22:36:02 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - Checking the system...
2024-09-15 22:36:02 [main] [34mINFO [0;39m o.testcontainers.DockerClientFactory - âœ”ï¸Ž Docker server version should be at least 1.6.0
2024-09-15 22:36:02 [main] [34mINFO [0;39m tc.mongo:latest - Creating container for image: mongo:latest
2024-09-15 22:36:02 [main] [34mINFO [0;39m tc.mongo:latest - Container mongo:latest is starting: eb8ac9b356b652d3b489fde704355f4f0289204e581adf6c9311e388ee729857
2024-09-15 22:36:03 [main] [34mINFO [0;39m tc.mongo:latest - Container mongo:latest started in PT0.734671902S
2024-09-15 22:36:04 [main] [34mINFO [0;39m c.z.c.i.r.SnapshotRepositoryIT - Starting SnapshotRepositoryIT using Java 17.0.8 with PID 552348 (started by anduser in /home/anduser/dev/assessment/assessment-m2/consumer)
2024-09-15 22:36:04 [main] [34mINFO [0;39m c.z.c.i.r.SnapshotRepositoryIT - No active profile set, falling back to 1 default profile: "default"
2024-09-15 22:36:04 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2024-09-15 22:36:04 [main] [34mINFO [0;39m o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 31 ms. Found 2 MongoDB repository interfaces.
2024-09-15 22:36:04 [main] [34mINFO [0;39m org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.0.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "6.8.0-40-generic"}, "platform": "Java/Amazon.com Inc./17.0.8+7-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@1b3a9ef4, com.mongodb.Jep395RecordCodecProvider@7a1371, com.mongodb.KotlinCodecProvider@6c6928c]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:33858], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
2024-09-15 22:36:04 [cluster-ClusterId{value='66e7291426cdbc7fd8b9722a', description='null'}-localhost:33858] [34mINFO [0;39m org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:33858, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16529976, setName='docker-rs', canonicalAddress=eb8ac9b356b6:27017, hosts=[eb8ac9b356b6:27017], passives=[], arbiters=[], primary='eb8ac9b356b6:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000001, setVersion=1, topologyVersion=TopologyVersion{processId=66e729128a84d7648950c5e9, counter=6}, lastWriteDate=Sun Sep 15 22:36:04 GET 2024, lastUpdateTimeNanos=33681932547178}
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:36:05 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:36:05 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726425365510
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Subscribed to topic(s): UpdateCustomerAddressEventTopic
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:36:05 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:36:05 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726425365530
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Subscribed to topic(s): DeleteCustomerEventTopic
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:36:05 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:36:05 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726425365538
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Subscribed to topic(s): CreateCustomerEventTopic
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [http://localhost:19092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-testConsumer-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testConsumer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2024-09-15 22:36:05 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:36:05 [main] [34mINFO [0;39m i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = true
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.consumer.ConsumerConfig - These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.7.1
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka commitId: e2494e6ffb89f828
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1726425365544
2024-09-15 22:36:05 [main] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Subscribed to topic(s): UpdateCustomerNameEventTopic
2024-09-15 22:36:05 [main] [34mINFO [0;39m c.z.c.i.r.SnapshotRepositoryIT - Started SnapshotRepositoryIT in 1.369 seconds (process running for 4.843)
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:05 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:06 [cluster-ClusterId{value='66e7291426cdbc7fd8b9722a', description='null'}-localhost:33858] [34mINFO [0;39m org.mongodb.driver.cluster - Exception in monitor thread while connecting to server localhost:33858
com.mongodb.MongoSocketReadException: Prematurely reached end of stream
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:178)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:196)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:716)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:580)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:428)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:381)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:221)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:153)
	at java.base/java.lang.Thread.run(Thread.java:833)
2024-09-15 22:36:06 [cluster-ClusterId{value='66e7291426cdbc7fd8b9722a', description='null'}-localhost:33858] [34mINFO [0;39m org.mongodb.driver.cluster - Exception in monitor thread while connecting to server localhost:33858
com.mongodb.MongoSocketReadException: Exception receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:707)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:583)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:428)
	at com.mongodb.internal.connection.InternalStreamConnection.sendAndReceive(InternalStreamConnection.java:354)
	at com.mongodb.internal.connection.CommandHelper.sendAndReceive(CommandHelper.java:92)
	at com.mongodb.internal.connection.CommandHelper.executeCommand(CommandHelper.java:48)
	at com.mongodb.internal.connection.InternalStreamConnectionInitializer.initializeConnectionDescription(InternalStreamConnectionInitializer.java:130)
	at com.mongodb.internal.connection.InternalStreamConnectionInitializer.startHandshake(InternalStreamConnectionInitializer.java:78)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:203)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:193)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:153)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:328)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:176)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:196)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:716)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:580)
	... 10 common frames omitted
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Node -1 disconnected.
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Connection to node -1 (localhost/127.0.0.1:19092) could not be established. Node may not be available.
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [31mWARN [0;39m o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Bootstrap broker localhost:19092 (id: -1 rack: null) disconnected
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.LegacyKafkaConsumer - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Unsubscribed all topics or patterns and assigned partitions
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-2, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-1, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-3, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-testConsumer-4, groupId=testConsumer] Request joining group due to: consumer pro-actively leaving the group
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-4 unregistered
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-3 unregistered
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-1 unregistered
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-testConsumer-2 unregistered
2024-09-15 22:36:06 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [34mINFO [0;39m o.s.k.l.KafkaMessageListenerContainer - testConsumer: Consumer stopped
